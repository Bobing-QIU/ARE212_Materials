{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4bac6c8",
   "metadata": {},
   "source": [
    "# Question 3 \n",
    "## (4)\n",
    "First we define the functions we need for GMM estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c999cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import inv \n",
    "from scipy.stats import distributions as iid \n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#From here: https://stackoverflow.com/questions/4740172/how-do-you-a-double-factorial-in-python\n",
    "def doublefactorial(n):\n",
    "     if n <= 0:\n",
    "         return 1\n",
    "     else:\n",
    "         return n * doublefactorial(n-2)\n",
    "\n",
    "    \n",
    "def gj(b, x, k): \n",
    "    '''\n",
    "    b: [mu, sigma], parameters for normal dist.\n",
    "    x: a single observaton\n",
    "    k: number of moments\n",
    "    '''\n",
    "    (mu, sigma) = b\n",
    "    res = []\n",
    "    for i in range(1,k+1):\n",
    "        if (i % 2) == 0:\n",
    "            xk = (x - mu) ** i  - (sigma**i) * doublefactorial(i-1)\n",
    "        else: \n",
    "            xk = (x - mu) ** i \n",
    "        res.append(xk)\n",
    "    return res\n",
    "\n",
    "\n",
    "def gN(b, x_lst, k):\n",
    "    '''\n",
    "    Average of gj across all observations\n",
    "    b: [mu, sigma], parameters for normal dist.\n",
    "    x_lst: list of all observations\n",
    "    k: number of moments\n",
    "    '''\n",
    "    return np.mean([gj(b, x_lst[j], k) for j in range(len(x_lst))], axis=0)\n",
    "\n",
    "\n",
    "def Omegahat(b, x_lst, k):\n",
    "    e = np.array([gj(b, x_lst[j], k) for j in range(len(x_lst))])\n",
    "\n",
    "    # Recenter! We have Eu=0 under null.\n",
    "    # Important to use this information.\n",
    "    e = e - e.mean(axis=0)\n",
    "    \n",
    "    return e.T@e/e.shape[0]\n",
    "\n",
    "\n",
    "def J(b, W, x_lst, k): \n",
    "    m = gN(b, x_lst, k) # Sample moments @ b\n",
    "    N = len(x_lst)\n",
    "\n",
    "    return (N*m.T@W@m) # Scale by sample size\n",
    "\n",
    "\n",
    "def two_step_gmm(x_lst, k):\n",
    "    # First step uses identity weighting matrix; use mean and variance as initial guess \n",
    "    W1 = np.eye(len(gj([0, 1], x_lst[0], k)))\n",
    "    b1 = minimize(lambda b: J(b, W1, x_lst, k), [np.mean(x_lst), np.var(x_lst)]).x \n",
    "\n",
    "    # Construct 2nd step weighting matrix using first step estimate of beta\n",
    "    W2 = inv(Omegahat(b1, x_lst, k))\n",
    "\n",
    "    return minimize(lambda b: J(b, W2, x_lst, k), b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125864f",
   "metadata": {},
   "source": [
    "Then we generate a sample from random normal distribution and show that this sample could pass the test. We also show that a sample generated from a uniform distribution cannot pass the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0d417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal distribution: b = [1.92492118 1.98066456], J = 5.659871260160289, Critical J = 5.991464547107983\n",
      "Uniform distribution: b = [ 2.98350648 -0.43532796], J = 370.80781612264775, Critical J = 5.991464547107983\n"
     ]
    }
   ],
   "source": [
    "# Estimation parameters\n",
    "N = 1000\n",
    "k = 4\n",
    "mu, sigma = [2, 2]\n",
    "\n",
    "# Limiting distribution of criterion (under null)\n",
    "limiting_J = iid.chi2(k-2)\n",
    "\n",
    "# Normal distribution \n",
    "X_norm = iid.norm.rvs(loc=mu, scale=sigma, size=(N, )) \n",
    "soltn = two_step_gmm(X_norm, k)\n",
    "print(f'Normal distribution: b = {soltn.x}, J = {soltn.fun}, Critical J = {limiting_J.isf(0.05)}')\n",
    "\n",
    "# Uniform distribution \n",
    "X_uni = iid.uniform.rvs(loc=mu, scale=sigma, size=(N, )) \n",
    "soltn_uni = two_step_gmm(X_uni, k)\n",
    "print(f'Uniform distribution: b = {soltn_uni.x}, J = {soltn_uni.fun}, Critical J = {limiting_J.isf(0.05)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592b51c",
   "metadata": {},
   "source": [
    "## (5)\n",
    "To investigate the optimal choice of $k$, we vary the range of $k$ to see how the test performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4a9eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3: b = [2.06586922 3.01092456], J = 0.02971106397668757, Critical J = 3.8414588206941285\n",
      "k = 4: b = [2.06564742 3.01077606], J = 0.03070175890851452, Critical J = 5.991464547107983\n",
      "k = 5: b = [2.05946818 3.00318949], J = 1.9512528961685092, Critical J = 7.814727903251178\n",
      "k = 6: b = [2.06660942 2.98089532], J = 2.4884012435271545, Critical J = 9.487729036781158\n",
      "k = 7: b = [2.07951766 2.97968779], J = 2.601178275600883, Critical J = 11.070497693516355\n",
      "k = 8: b = [2.11100567 2.7943187 ], J = 20.252114183883975, Critical J = 12.59158724374398\n",
      "k = 9: b = [2.15686754 2.79082664], J = 22.18252060789257, Critical J = 14.067140449340167\n",
      "k = 10: b = [15.61816404  7.04066872], J = 3.423908921120107e+16, Critical J = 15.507313055865454\n",
      "k = 11: b = [6.62664504 0.4271115 ], J = 18590.99169981852, Critical J = 16.91897760462045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bobing\\AppData\\Local\\Temp\\ipykernel_40332\\1302096430.py:55: RuntimeWarning: overflow encountered in matmul\n",
      "  return (N*m.T@W@m) # Scale by sample size\n",
      "C:\\Users\\Bobing\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "C:\\Users\\Bobing\\AppData\\Local\\Temp\\ipykernel_40332\\1302096430.py:55: RuntimeWarning: invalid value encountered in matmul\n",
      "  return (N*m.T@W@m) # Scale by sample size\n",
      "C:\\Users\\Bobing\\AppData\\Local\\Temp\\ipykernel_40332\\1302096430.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "  xk = (x - mu) ** i  - (sigma**i) * doublefactorial(i-1)\n",
      "C:\\Users\\Bobing\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\Bobing\\AppData\\Local\\Temp\\ipykernel_40332\\1302096430.py:26: RuntimeWarning: overflow encountered in double_scalars\n",
      "  xk = (x - mu) ** i\n",
      "C:\\Users\\Bobing\\AppData\\Local\\Temp\\ipykernel_40332\\1302096430.py:24: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  xk = (x - mu) ** i  - (sigma**i) * doublefactorial(i-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 12: b = [-6.24699257e+10 -9.85382325e+03], J = -5.050314449343852e+242, Critical J = 18.30703805327515\n",
      "k = 13: b = [11.9853072   1.47705737], J = 46765811.728515625, Critical J = 19.67513757268249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bobing\\AppData\\Local\\Temp\\ipykernel_40332\\1302096430.py:55: RuntimeWarning: overflow encountered in matmul\n",
      "  return (N*m.T@W@m) # Scale by sample size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 14: b = [17.82378389 53.68739115], J = -1.4308731374060264e+36, Critical J = 21.02606981748307\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "mu, sigma = [2, 3]\n",
    "X = iid.norm.rvs(loc=mu, scale=sigma, size=(N, )) \n",
    "for k in range(3, 15): \n",
    "    soltn = two_step_gmm(X, k)\n",
    "    limiting_J = iid.chi2(k-2)\n",
    "    print(f'k = {k}: b = {soltn.x}, J = {soltn.fun}, Critical J = {limiting_J.isf(0.05)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0c1a5",
   "metadata": {},
   "source": [
    "## (6)\n",
    "We estimate the parameters $(\\mu, \\sigma)$ using maximum likelihood approach and compare them with that from GMM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e63f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE: b = [2.06582581 3.0100923 ]\n"
     ]
    }
   ],
   "source": [
    "def neg_log_likelihood(b, x_lst): \n",
    "    mu, sigma = b\n",
    "    n = len(x_lst)\n",
    "    ll = -n/2*np.log(2*np.pi*sigma**2) - 1/(2*sigma**2)*np.sum((x_lst-mu)**2)\n",
    "    return -ll \n",
    "\n",
    "def MLE(x_lst): \n",
    "    initial_guess = [np.mean(x_lst), np.var(x_lst)]\n",
    "    return minimize(lambda b: neg_log_likelihood(b, x_lst), initial_guess)\n",
    "\n",
    "soltn = MLE(X)\n",
    "print(f'MLE: b = {soltn.x}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
