{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8da0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import inv \n",
    "from scipy.stats import distributions as iid \n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#From here: https://stackoverflow.com/questions/4740172/how-do-you-a-double-factorial-in-python\n",
    "def doublefactorial(n):\n",
    "     if n <= 0:\n",
    "         return 1\n",
    "     else:\n",
    "         return n * doublefactorial(n-2)\n",
    "\n",
    "    \n",
    "def gj(b, x, k): \n",
    "    '''\n",
    "    b: [mu, sigma], parameters for normal dist.\n",
    "    x: a single observaton\n",
    "    k: number of moments\n",
    "    '''\n",
    "    (mu, sigma) = b\n",
    "    res = []\n",
    "    for i in range(1,k+1):\n",
    "        if (i % 2) == 0:\n",
    "            xk = (x - mu) ** i  - (sigma**i) * doublefactorial(i-1)\n",
    "        else: \n",
    "            xk = (x - mu) ** i \n",
    "        res.append(xk)\n",
    "    return res\n",
    "\n",
    "\n",
    "def gN(b, x_lst, k):\n",
    "    '''\n",
    "    Average of gj across all observations\n",
    "    b: [mu, sigma], parameters for normal dist.\n",
    "    x_lst: list of all observations\n",
    "    k: number of moments\n",
    "    '''\n",
    "    return np.mean([gj(b, x_lst[j], k) for j in range(len(x_lst))], axis=0)\n",
    "\n",
    "\n",
    "def Omegahat(b, x_lst, k):\n",
    "    e = np.array([gj(b, x_lst[j], k) for j in range(len(x_lst))])\n",
    "\n",
    "    # Recenter! We have Eu=0 under null.\n",
    "    # Important to use this information.\n",
    "    e = e - e.mean(axis=0)\n",
    "    \n",
    "    return e.T@e/e.shape[0]\n",
    "\n",
    "\n",
    "def J(b, W, x_lst, k): \n",
    "    m = gN(b, x_lst, k) # Sample moments @ b\n",
    "    N = len(x_lst)\n",
    "\n",
    "    return (N*m.T@W@m) # Scale by sample size\n",
    "\n",
    "\n",
    "def two_step_gmm(x_lst, k):\n",
    "    # First step uses identity weighting matrix; use mean and variance as initial guess \n",
    "    W1 = np.eye(len(gj([0, 1], x_lst[0], k)))\n",
    "    b1 = minimize(lambda b: J(b, W1, x_lst, k), [np.mean(x_lst), np.var(x_lst)]).x \n",
    "\n",
    "    # Construct 2nd step weighting matrix using first step estimate of beta\n",
    "    W2 = inv(Omegahat(b1, x_lst, k))\n",
    "\n",
    "    return minimize(lambda b: J(b, W2, x_lst, k), b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ffaf988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 0.749096006795324\n",
       "        x: [ 1.904e+00  1.923e+00]\n",
       "      nit: 4\n",
       "      jac: [ 4.545e-07  6.832e-06]\n",
       " hess_inv: [[ 1.860e-03  2.407e-05]\n",
       "            [ 2.407e-05  8.571e-04]]\n",
       "     nfev: 21\n",
       "     njev: 7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iid.norm.rvs(loc=2, scale=2, size=(1000, )) \n",
    "k = 4\n",
    "two_step_gmm(X, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c78bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
