{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c717a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy.stats import distributions as iid\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt \n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3c68dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata('/Users/cassturk/Downloads/angrist-krueger91.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "421068d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "85e8c954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10000)\n",
      "(21, 10000)\n",
      "(60, 10000)\n"
     ]
    }
   ],
   "source": [
    "#readying data\n",
    "j =pd.get_dummies(data['yob'])\n",
    "\n",
    "j = j.drop(columns = [1939])\n",
    "\n",
    "m = data['yob'].astype(str)+data['qob'].astype(str)\n",
    "l = pd.get_dummies(m)\n",
    "\n",
    "n = pd.get_dummies(data['region'])\n",
    "\n",
    "d = np.array([list(data['logwage'])])\n",
    "a= np.array([list(data['edu'])])\n",
    "\n",
    "\n",
    "#print(np.array(data['black']).T.shape)\n",
    "\n",
    "b = np.r_[a,np.array(j).T, np.array([list(data['black'])]), np.array([list(data['smsa'])]), np.array([list(data['married'])]) ,np.array(n).T]\n",
    "\n",
    "z = np.r_[np.array(l).T, np.array(j).T, np.array([list(data['black'])]), \n",
    "              np.array([list(data['smsa'])]), np.array([list(data['married'])]), np.array(n).T]\n",
    "\n",
    "print(d.shape)\n",
    "print(b.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "248c1e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06185895,  0.04466469,  0.03536557,  0.04112089,  0.03544588,\n",
       "        0.03493746,  0.0100583 , -0.01264055, -0.05430268, -0.05522192,\n",
       "        4.04543096,  0.15040736,  0.20071592,  0.61664573,  0.69012796,\n",
       "        0.33737827,  0.54841281,  0.56243703,  0.3914977 ,  0.5445062 ,\n",
       "        0.35442527])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting values for covariates\n",
    "j =pd.get_dummies(data['yob'])\n",
    "\n",
    "m = data['yob'].astype(str)+data['qob'].astype(str)\n",
    "\n",
    "\n",
    "l = pd.get_dummies(m)\n",
    "\n",
    "l = l.drop(columns=['19393', '19391', '19392', '19394', '19303', '19313', '19323', \n",
    "                        '19333', '19343','19353', '19363','19373'])\n",
    "j = j.drop(columns = [1939])\n",
    "\n",
    "d = np.array([list(data['logwage'])])\n",
    "a= np.array([list(data['edu'])])\n",
    "\n",
    "b = np.r_[a,np.array(j).T, np.array([list(data['black'])]), np.array([list(data['smsa'])]), np.array([list(data['married'])]) ,np.array(n).T]\n",
    "\n",
    "model = sm.OLS(d.T,b.T)\n",
    "results = model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "caf0ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [0.04466469,  0.03536557,  0.04112089,  0.03544588,\n",
    "        0.03493746,  0.0100583 , -0.01264055, -0.05430268, -0.05522192,\n",
    "        4.04543096,  0.15040736,  0.20071592,  0.61664573,  0.69012796,\n",
    "        0.33737827,  0.54841281,  0.56243703,  0.3914977 ,  0.5445062 ,\n",
    "        0.35442527]\n",
    "\n",
    "def p_val(y, x, Z, beta0): \n",
    "    '''\n",
    "    Compute p-value from an F test on \\gamma = 0 \n",
    "    \n",
    "    Input: y, x, Z, beta0 (guess of true beta)\n",
    "    \n",
    "    Ouput: p-value \n",
    "    '''\n",
    "    hmm = beta0\n",
    "    beta1 = [hmm]\n",
    "    for item in vals:\n",
    "        beta1.append(item )\n",
    "    beta1 = np.array([beta1])\n",
    "    #print(np.array([y.squeeze()]))\n",
    "    #print(y.shape)\n",
    "    #print((beta1@x.T).T.shape)\n",
    "    #print(Z.shape)\n",
    "    \n",
    "    \n",
    "    yh = np.subtract(y , (beta1@x.T).T) # transform the LHS var\n",
    "    #print(yh.shape)\n",
    "    #print(yh)\n",
    "    model = sm.OLS(yh, Z)\n",
    "    lm = model.fit() # fit the linear model \n",
    "    #print(lm.params)\n",
    "    return lm.f_pvalue # return p value from F test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8ede9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def max_p(y, x, Z):\n",
    "    '''\n",
    "    Obtain the estimate beta0 that max p-value \n",
    "    \n",
    "    Input: y, x, Z \n",
    "    \n",
    "    Output: beta0, max p-value \n",
    "    '''\n",
    "    beta_lst = list(np.arange(0, 2, 0.01)) # Try beta0 in this range \n",
    "    p_lst = [] \n",
    "    \n",
    "    for i in range(len(beta_lst)): # get p-value for each corresponding beta0\n",
    "        p_lst.append(p_val(y, x, Z, beta_lst[i])) \n",
    "    p_dict = dict(zip(beta_lst, p_lst))\n",
    "    \n",
    "    max_beta = max(p_dict, key=p_dict.get)\n",
    "    max_pval = p_dict[max_beta] # maxinmal pval and beta \n",
    "    \n",
    "    ci_beta = list(dict(filter(lambda item: item[1]>=0.05, p_dict.items())).keys()) \n",
    "    ci = [ci_beta[0], ci_beta[-1]] # confidence interval \n",
    "    \n",
    "    return max_beta, max_pval, ci\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ab74dae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10000)\n",
      "(21, 10000)\n",
      "(60, 10000)\n"
     ]
    }
   ],
   "source": [
    "#readying data\n",
    "j =pd.get_dummies(data['yob'])\n",
    "\n",
    "j = j.drop(columns = [1939])\n",
    "\n",
    "m = data['yob'].astype(str)+data['qob'].astype(str)\n",
    "l = pd.get_dummies(m)\n",
    "\n",
    "n = pd.get_dummies(data['region'])\n",
    "\n",
    "d = np.array([list(data['logwage'])])\n",
    "a= np.array([list(data['edu'])])\n",
    "\n",
    "\n",
    "#print(np.array(data['black']).T.shape)\n",
    "\n",
    "b = np.r_[a,np.array(j).T, np.array([list(data['black'])]), np.array([list(data['smsa'])]), np.array([list(data['married'])]) ,np.array(n).T]\n",
    "\n",
    "z = np.r_[np.array(l).T, np.array(j).T, np.array([list(data['black'])]), \n",
    "              np.array([list(data['smsa'])]), np.array([list(data['married'])]), np.array(n).T]\n",
    "\n",
    "print(d.shape)\n",
    "print(b.shape)\n",
    "print(z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8e496a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.06, 0.9583037698654765, [0.03, 0.09])\n",
      "The estimated coefficient is 0.06, the corresponding maximal p-value is 0.9583037698654765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(max_p(d.T, b.T, z.T))\n",
    "\n",
    "b, pval, ci = max_p(d.T, b.T, z.T) # estimate beta\n",
    "print(f'The estimated coefficient is {b}, the corresponding maximal p-value is {pval}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6e6b5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sls(y, X, Z):\n",
    "    '''\n",
    "    Estimate 2 stage least squares given data on y, X and Z.\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    y (Nx1 np.array)\n",
    "    X (Nx1 np.array)\n",
    "    Z (Nxl np.array)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    beta_hat, vb_beta_hat\n",
    "    '''\n",
    "    y = np.array(y)\n",
    "    X = np.array(X)\n",
    "    Z = np.array(Z)\n",
    "    ZX = np.transpose(Z)@X\n",
    "    ZX_inv = np.linalg.pinv(ZX)#using pseuodo-inverse\n",
    "    Zy = np.transpose(Z)@y\n",
    "    ZZ = np.transpose(Z)@Z\n",
    "    ZZ_inv = np.linalg.pinv(ZZ)\n",
    "    #Beta_IV2SLS = ZX_inv@ZY\n",
    "    beta_hat = np.linalg.pinv(np.transpose(ZX)@ZZ_inv@ZX)@(np.transpose(ZX)@ZZ_inv@Zy)\n",
    "    e = y - X@beta_hat\n",
    "    SSR = np.transpose(e)@e\n",
    "    N = X.shape[0]\n",
    "    vcv = (SSR/N)*np.linalg.pinv(np.transpose(ZX)@ZZ_inv@ZX)\n",
    "    K = X.shape[1]\n",
    "    se_beta_hat = np.zeros(K)\n",
    "    for i in range(K):\n",
    "          se_beta_hat[i] = np.sqrt(vcv[i,i])\n",
    "            \n",
    "    return beta_hat, se_beta_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7b9b7b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated coefficient from 2SLS is 0.09708617398871411, and the confidence interval is (0.017785438763933598, 0.17638690921349462).\n",
      "(1, 10000)\n",
      "(21, 10000)\n",
      "(60, 10000)\n"
     ]
    }
   ],
   "source": [
    "b_2sls, se_2sls = two_sls(d.T, b.T, z.T)\n",
    "print(f\"The estimated coefficient from 2SLS is {b_2sls[0][0]}, and the confidence interval is {b_2sls[0][0] - 1.96*se_2sls[0], b_2sls[0][0] + 1.96*se_2sls[0]}.\")\n",
    "\n",
    "print(d.shape)\n",
    "print(b.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39aebae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
