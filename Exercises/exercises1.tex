% Created 2022-03-14 Mon 22:10
% Intended LaTeX compiler: pdflatex
\RequirePackage{rotating}
\documentclass[12pt]{amsart}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{hyperref}
\tolerance=1000
\usepackage[authordate-trad,backend=biber,natbib]{biblatex-chicago}
\addbibresource{main.bib}
\addbibresource{ligon.bib}
\renewcommand{\refname}{}
\usepackage{booktabs}
\usepackage{minted}
\usepackage{wasysym}
\newcommand{\Cov}{\ensuremath{\mbox{Cov}}}
\renewcommand{\Pr}{\ensuremath{\mbox{Pr}}}
\newcommand{\Eq}[1]{(\ref{eq:#1})}
\usepackage{bm}\usepackage{econometrics}
\newcommand{\T}{\top}
\newtheorem{proposition}{Proposition} \newcommand{\Prop}[1]{Proposition \ref{prop:#1}}
%\newtheorem{problem}{Problem} \newcommand{\Prob}[1]{Problem \ref{prob:#1}}
%\newtheorem{theorem}{Theorem} \newcommand{\Thm}[1]{Theorem \ref{thm:#1}}
%\newtheorem{corollary}{Corollary} \newcommand{\Cor}[1]{Corollary \ref{cor:#1}}
%\newtheorem{remark}{Remark} \newcommand{\Rem}[1]{Remark \ref{rem:#1}}
%\newtheorem{condition}{Condition} \newcommand{\Cond}[1]{Condition \ref{cond:#1}}
%\newtheorem{lemma}{Lemma} \newcommand{\Lem}[1]{Lemma \ref{lem:#1}}
%\newtheorem{assumption}{Assumption} \newcommand{\Ass}[1]{Assumption \ref{ass:#1}}
\newcommand{\Fig}[1]{Figure \ref{fig:#1}} \newcommand{\Tab}[1]{Table \ref{tab:#1}}
\usepackage{dsfont}\newcommand{\one}{\ensuremath{\mathds{1}}}
\usepackage{xcolor}
\newcommand{\rv}[1]{\ensuremath{\textcolor{red}{#1}{}}}
%\newcommand{\rv}[1]{\ensuremath{{}_{rv}{#1}{}}}
%\newcommand{\rv}[1]{\ensuremath{\underline{#1}{}}}
\newcommand{\rvy}{\rv{y}}
\newcommand{\rvX}{\rv{X}}
\newcommand{\rvx}{\rv{x}}
\newcommand{\rvu}{\rv{u}}
\renewcommand{\do}[1]{\ensuremath{\mbox{do}(#1)}}
\renewcommand{\E}{\ensuremath{\mathds{E}}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\author{ligon}
\date{\today}
\title{Exercises (Topic 1)}
\hypersetup{
 pdfauthor={ligon},
 pdftitle={Exercises (Topic 1)},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.0.50 (Org mode 9.4.5)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

\begin{enumerate}
\item From ARE210, recall (Section 9 in Mahajan's ``Handout 1'') the rule for
computing the distribution of certain transformations of random
variables (The ``inverse Jacobian rule'').

Let \((\rvx,rvy)\) be independently distributed continuous random
variables possessing densities \(f_x\) and \(f_y\).  Let \(\rv{z} = \rvx +
      \rvy\).  Use the rule to obtain an expression for the distribution
of \(z\).

\item Let \(A\) be an \(m\times n\) matrix.  A matrix \(A^-\) is a
\emph{generalized inverse} of \(A\) if \(AA^-A=A\).  Such a generalized
inverse can be shown to always exist.  If \(A\) is a matrix
of zeros, what can we say about \(A^-\)?

\item Econometricians spend a great deal of time writing down
linear regressions relating an object ``Why'' to an object ``Ex'', but
sometimes use quite distinct notations to express this
regression.  Following our discussion in class, suggest a
notation for each of the three following cases:

\begin{enumerate}
\item ``Why'' is a scalar random variable, while ``Ex'' is a vector
random variable;

\item ``Why'' is a single \emph{realization} of a scalar random variable,
while ``Ex'' is similarly a single \emph{realization};

\item ``Why'' is a \emph{vector} of \(N\) realizations, while ``Ex'' is
similarly a \emph{matrix} of realizations.
\end{enumerate}

\item Let \(\mA\) be an \(m\times n\) matrix.  A matrix \(\mA^+\) is the
``Moore-Penrose'' generalized inverse if:

\begin{enumerate}
\item \(\mA\mA^+\mA = \mA\);
\item \(\mA^+\mA\mA^+ = \mA^+\);
\item \(\mA^+\mA\) is symmetric; and
\item \(\mA\mA^+\) is symmetric.
\end{enumerate}

If \(\mA\) is a matrix of zeros, what is \(\mA^+\)?

\item Definition: Let \(\mA\) be an \(n\times m\) matrix of rank \(r\).  If \(\mA = \mL\mR\), where \(\mL\) is a
\(n\times r\) full column rank matrix, and \(\mR\) is a \(r\times m\) full row rank matrix, then \(\mL\mR\)
is a \emph{full rank factorization} of \(\mA\).

Fact: Provided only that \(r>0\), the Moore-Penrose inverse \(\mA^+ = \mR'(\mL'\mA\mR')^{-1}\mL'\) exists and is unique.

Use this expression for the Moore-Penrose inverse to solve for
\(\vb\) in the (matrix) form of the regression \(\vy = \mXb + \vu\)
if \(\mX'\vu=0\).
\end{enumerate}
\end{document}